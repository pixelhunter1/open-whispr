# Local Whisper Integration Guide

## ‚úÖ What We've Accomplished

Your OpenScribe app has been successfully refactored to support **local Whisper models** in addition to the OpenAI API. Here's what's been implemented:

### üîß Technical Implementation

1. **Python Bridge Script** (`whisper_bridge.py`)
   - Handles local audio transcription using OpenAI's Whisper models
   - Supports all Whisper models: tiny, base, small, medium, large, turbo
   - JSON output for integration with Electron app
   - Proper error handling and cleanup

2. **Enhanced Main Process** (`main.js`)
   - New IPC handlers for local Whisper transcription
   - Python executable detection across different systems
   - Whisper installation checking
   - Temporary file management with cleanup
   - 30-second timeout protection

3. **Updated Preload Script** (`preload.js`)
   - New IPC methods exposed to renderer
   - Type-safe interfaces for TypeScript

4. **Enhanced React App** (`src/App.jsx`)
   - Automatic fallback from local to OpenAI API
   - User preference storage in localStorage
   - Model selection support
   - Smart error handling

5. **Advanced Control Panel** (`src/components/ControlPanel.tsx`)
   - Complete UI for Whisper engine selection
   - Model selection dropdown with descriptions
   - Installation status checking
   - Privacy information display
   - Settings persistence

## üöÄ How to Use Local Whisper

### Step 1: Open the Control Panel
- Right-click the app tray icon (macOS) or use the overlay
- Navigate to "Whisper Engine Settings"

### Step 2: Enable Local Whisper
- Check the "Use Local Whisper (Privacy Mode)" checkbox
- Select your desired model:
  - **Tiny**: Fastest, lowest quality (39M params)
  - **Base**: Balanced speed/quality (74M params) - Recommended
  - **Small**: Better quality, slower (244M params)
  - **Medium**: High quality, much slower (769M params)
  - **Large**: Best quality, very slow (1550M params)
  - **Turbo**: Fast with good quality (809M params)

### Step 3: Save Settings
- Click "Save Whisper Settings"
- The app will now use local processing for all new transcriptions

## üîí Privacy Benefits

### Local Whisper Mode
- ‚úÖ **Complete Privacy**: Audio never leaves your device
- ‚úÖ **No Internet Required**: Works offline (after model download)
- ‚úÖ **No API Costs**: Free to use after initial setup
- ‚úÖ **Faster Response**: No network latency
- ‚ö†Ô∏è **Higher Resource Usage**: Uses CPU/memory for processing

### OpenAI API Mode  
- ‚ö†Ô∏è **Audio Sent to OpenAI**: Audio data transmitted to servers
- ‚ö†Ô∏è **Internet Required**: Needs active connection
- ‚ö†Ô∏è **API Costs**: Charges per minute of audio
- ‚úÖ **Fast & Efficient**: Minimal local resource usage
- ‚úÖ **Always Latest Model**: OpenAI's most advanced model

## üì¶ Requirements (Already Installed)

The following are already installed and configured:

- ‚úÖ **Python 3**: Installed via Homebrew
- ‚úÖ **FFmpeg**: Installed via Homebrew  
- ‚úÖ **OpenAI Whisper**: Installed via pip3
- ‚úÖ **Bridge Script**: Created and configured
- ‚úÖ **App Integration**: Fully implemented

## üß™ Testing Your Setup

### Test 1: Check Installation Status
1. Open the Control Panel
2. Look at the "Whisper Engine Settings" card
3. You should see "‚úÖ Installed" next to the Local Whisper checkbox

### Test 2: Test Local Transcription
1. Enable "Use Local Whisper" in Control Panel
2. Select "base" model (recommended for testing)
3. Save settings
4. Press the backtick key (`) to start dictation
5. Speak clearly for 2-3 seconds
6. Press backtick again to stop
7. The transcription should appear and paste automatically

### Test 3: Model Download (First Time)
- The first time you use a model, Whisper will download it automatically
- This may take a few minutes depending on your internet speed
- Subsequent uses will be much faster

## üîÑ Fallback Behavior

The app is configured with intelligent fallback:

1. **Primary**: Use local Whisper if enabled and working
2. **Fallback**: Automatically switch to OpenAI API if local fails
3. **Error Handling**: Clear messages about what's happening

## üìä Model Performance Guide

| Model  | Size  | Speed    | Quality | Memory | Best For |
|--------|-------|----------|---------|--------|----------|
| Tiny   | 39M   | Fastest  | Basic   | ~1GB   | Quick notes |
| Base   | 74M   | Fast     | Good    | ~1GB   | **Recommended** |
| Small  | 244M  | Medium   | Better  | ~2GB   | Professional use |
| Medium | 769M  | Slow     | High    | ~5GB   | High accuracy needed |
| Large  | 1550M | Slowest  | Best    | ~10GB  | Maximum quality |
| Turbo  | 809M  | Fast     | High    | ~6GB   | Best balance |

## üõ† Troubleshooting

### "‚ùå Not Found" Status
If you see this status:
1. Click "Recheck Installation" button
2. Restart the app completely
3. Check Console logs for Python/Whisper errors

### Transcription Fails
1. Check your microphone permissions
2. Verify the model downloaded successfully
3. Try switching to a smaller model (tiny/base)
4. Check Console logs for detailed error messages

### Slow Performance
1. Use smaller models (tiny, base)
2. Close other resource-intensive apps
3. Check your system's available memory

### Model Download Issues
1. Ensure stable internet connection
2. Check available disk space (~2-15GB depending on model)
3. Try smaller model first

## üîß Advanced Configuration

### Custom Python Path
If you need to use a specific Python installation:
1. Edit `main.js`
2. Modify the `findPythonExecutable()` function
3. Add your Python path to the `possiblePaths` array

### Model Storage Location
Models are downloaded to `~/.cache/whisper/` by default.
You can change this by modifying the bridge script.

### Timeout Settings
Current timeout is 30 seconds. To change:
1. Edit `main.js`
2. Find the `setTimeout` in the `transcribe-local-whisper` handler
3. Adjust the value (in milliseconds)

## üéØ Next Steps

Your app now supports both local and cloud transcription! You can:

1. **Switch modes anytime** via Control Panel
2. **Test different models** to find your preference
3. **Enjoy complete privacy** with local processing
4. **Keep API access** as a backup option

The integration is complete and ready for production use. All files have been modified and the Python bridge is fully functional.

## üìù Files Modified

- ‚úÖ `whisper_bridge.py` - New Python bridge script
- ‚úÖ `main.js` - Added local Whisper IPC handlers
- ‚úÖ `preload.js` - Added new IPC method exports
- ‚úÖ `src/App.jsx` - Enhanced with local/API switching
- ‚úÖ `src/components/ControlPanel.tsx` - New Whisper settings UI

Everything is ready to use! üéâ 